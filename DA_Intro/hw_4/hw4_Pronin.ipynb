{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение в анализ данных (первый семестр)\n",
    "## Домашнее задание №4 - Участие в конкурсе Quora Question Pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Что вам нужно будет сделать</b><br>\n",
    "До <b>23:59 7 мая</b> сделать хотя бы один submission в соревновании, а в промежуток <b>с 9 по 10 мая</b> выложить отчет (код в jupyter notebook, который генерирует ваше решение) в топик на kaggle, который я чуть позже создам (правила kaggle запрещают обмениваться кодом за пределами платформы).\n",
    "Баллы за это задание будут начисляться следующим образом (только при наличии отчета):<br>\n",
    "результат < 0.5 - 6 баллов<br>\n",
    "результат < 0.4 - 8 баллов<br>\n",
    "результат < 0.35 - 10 баллов<br>\n",
    "остальные критерии будут определены постфактум (при оценивании будут учитываться ваше место в лидерборде и отчет)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Подготовка</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импорт всех необходимых пакетов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import cPickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "import string\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics.pairwise import paired_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_submission(submission, name='submission', path='./answers', with_dttm=False):\n",
    "    suffix = '_' + datetime.now().strftime('%Y-%m-%d_%H-%M-%S') if with_dttm else ''\n",
    "    filename = os.path.join(path, '%s%s.csv' % (name, suffix))\n",
    "    submission.to_csv(filename, index=False)\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BOW_words_not_equal': (LogisticRegression(C=0.1, class_weight={0: 1.32, 1: 0.46}, dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1, max_iter=10000,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "            solver='sag', tol=0.0001, verbose=0, warm_start=False),\n",
       "  <2345796x9281 sparse matrix of type '<type 'numpy.int32'>'\n",
       "  \twith 29083038 stored elements in Compressed Sparse Row format>),\n",
       " 'TFIDF': (LogisticRegression(C=0.1, class_weight={0: 1.32, 1: 0.46}, dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1, max_iter=10000,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "            solver='sag', tol=0.0001, verbose=0, warm_start=False),\n",
       "  array([[ 0.66066394],\n",
       "         [ 0.38021914],\n",
       "         [ 0.31027794],\n",
       "         ..., \n",
       "         [ 1.        ],\n",
       "         [ 0.11289055],\n",
       "         [ 0.38710213]]))}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#models_and_test_matricies = {}\n",
    "#with open('models_and_test_matricies_2.pkl', 'r') as fid:\n",
    "    #models_and_test_matricies = cPickle.load(fid)\n",
    "#models_and_test_matricies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Загрузка и предобработка тренировочных данных</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
       "      <td>I'm a triple Capricorn (Sun, Moon and ascendan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>Should I buy tiago?</td>\n",
       "      <td>What keeps childern active and far from phone ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>How can I be a good geologist?</td>\n",
       "      <td>What should I do to be a great geologist?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>When do you use シ instead of し?</td>\n",
       "      <td>When do you use \"&amp;\" instead of \"and\"?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>Motorola (company): Can I hack my Charter Moto...</td>\n",
       "      <td>How do I hack Motorola DCX3400 for free internet?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "5   5    11    12  Astrology: I am a Capricorn Sun Cap moon and c...   \n",
       "6   6    13    14                                Should I buy tiago?   \n",
       "7   7    15    16                     How can I be a good geologist?   \n",
       "8   8    17    18                    When do you use シ instead of し?   \n",
       "9   9    19    20  Motorola (company): Can I hack my Charter Moto...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  \n",
       "5  I'm a triple Capricorn (Sun, Moon and ascendan...             1  \n",
       "6  What keeps childern active and far from phone ...             0  \n",
       "7          What should I do to be a great geologist?             1  \n",
       "8              When do you use \"&\" instead of \"and\"?             0  \n",
       "9  How do I hack Motorola DCX3400 for free internet?             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "train_df = train_df.dropna().reset_index(drop=True)\n",
    "train_df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_df = pd.read_csv('data/train.csv')\n",
    "#train_df = train_df.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Извлечение признаков: Bag of words (chars)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BOW = CountVectorizer(max_df=0.999, min_df=100, analyzer='char', \n",
    "                      ngram_range=(1,3), max_features=None, binary=True, lowercase=True)\n",
    "BOW.fit(pd.concat((train_df['question1'],train_df['question2'])).unique())\n",
    "\n",
    "BOW_q1 = BOW.transform(train_df.question1)\n",
    "BOW_q2 = BOW.transform(train_df.question2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Введём следующий признак:<br>\n",
    "0, если последовательность букв находится как в BOW первых вопросов, так и в BOW вторых вопросов, или отсутствует и там, и там<br>\n",
    "-1, если последовательность букв находится только в одном BOW, и отсутствует в другом<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404288, 8345)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_BOW_chars = -(BOW_q1 != BOW_q2).astype(int)\n",
    "y = train_df.is_duplicate.values\n",
    "X_BOW_chars.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Обучение модели на тренировочных данных</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Информация о весах классов взята [отсюда](https://www.kaggle.com/davidthaler/how-many-1-s-are-in-the-public-lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_lr_bow_chars = LogisticRegression(C=0.1, solver='sag', class_weight={1: 0.46, 0: 1.32}, max_iter=10000).fit(X_BOW_chars, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Загрука и обработка тестовых данных</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2345796 entries, 0 to 2345795\n",
      "Data columns (total 3 columns):\n",
      "test_id      int64\n",
      "question1    object\n",
      "question2    object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 53.7+ MB\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('data/test.csv')\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df.loc[test_df['question1'].isnull(), ['question1','question2']] = ''\n",
    "test_df.loc[test_df['question2'].isnull(), ['question1','question2']] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test_df = pd.read_csv('data/test.csv')\n",
    "#test_df.loc[test_df['question1'].isnull(), ['question1','question2']] = ''\n",
    "#test_df.loc[test_df['question2'].isnull(), ['question1','question2']] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "BOW_q1 = BOW.transform(test_df.loc[:,'question1'])\n",
    "gc.collect()\n",
    "BOW_q2 = BOW.transform(test_df.loc[:,'question2'])\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2345796, 8345)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_BOW_chars = -(BOW_q1 != BOW_q2).astype(int)\n",
    "X_BOW_chars.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Применение модели на тестовых данных</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted = model_lr_bow_chars.predict_proba(X_BOW_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Сохранение предсказаний</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2345796, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./answers\\\\submission_BOW_chars_2017-05-10_16-39-21.csv'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.concat([test_df.test_id.astype(int), pd.DataFrame(predicted[:,1], \n",
    "                                        columns=['is_duplicate'], index=test_df.index)], axis=1)\n",
    "print submission.shape\n",
    "save_submission(submission, 'submission_BOW_chars', with_dttm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#models_and_test_matricies['BOW_chars_not_equal'] = (model_lr_bow_chars, X_BOW_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#with open('models_and_test_matricies_2.pkl', 'wb') as fid:\n",
    "    #cPickle.dump(models_and_test_matricies, fid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3>Извлечение признаков: Bag of words (word) </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del_punct_trans_table = dict((ord(char), None) for char in string.punctuation)\n",
    "\n",
    "def nlp_preprocessor(sentence):\n",
    "    return delete_punctuation_unicode(sentence.lower())\n",
    "\n",
    "def nlp_tokenizer(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    ll = WordNetLemmatizer()\n",
    "    stemmer = SnowballStemmer(language='english', ignore_stopwords=True)\n",
    "    tokens = [ll.lemmatize(item) for item in tokens]\n",
    "    tokens = [stemmer.stem(item) for item in tokens]\n",
    "    return tokens\n",
    "\n",
    "def delete_punctuation_unicode(to_translate):\n",
    "    return to_translate.translate(del_punct_trans_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BOW = CountVectorizer(max_df=0.999, min_df=20, preprocessor=nlp_preprocessor, tokenizer=nlp_tokenizer, analyzer='word',\n",
    "                    max_features=None, binary=True)\n",
    "BOW.fit(pd.concat((train_df['question1'],train_df['question2'])).unique())\n",
    "\n",
    "BOW_q1 = BOW.transform(train_df.question1)\n",
    "BOW_q2 = BOW.transform(train_df.question2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404288, 9281)\n"
     ]
    }
   ],
   "source": [
    "y = train_df.is_duplicate.values\n",
    "X_BOW_words_not_equal = -(BOW_q1 != BOW_q2).astype(int)\n",
    "#X_ham_loss = paired_distances(BOW_q1, BOW_q2, metric=hamming_loss)\n",
    "print X_BOW_words_not_equal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_lr_BOW_words_not_equal = LogisticRegression(C=0.1, solver='sag', class_weight={1: 0.46, 0: 1.32}, \n",
    "                                                  max_iter=10000).fit(X_BOW_words_not_equal, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('data/test.csv')\n",
    "test_df.loc[test_df['question1'].isnull(), ['question1','question2']] = ''\n",
    "test_df.loc[test_df['question2'].isnull(), ['question1','question2']] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "BOW_q1 = BOW.transform(test_df.loc[:,'question1'])\n",
    "gc.collect()\n",
    "BOW_q2 = BOW.transform(test_df.loc[:,'question2'])\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2345796, 9281)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_BOW_words_not_equal = -(BOW_q1 != BOW_q2).astype(int)\n",
    "X_BOW_words_not_equal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del BOW_q1, BOW_q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = model_lr_BOW_words_not_equal.predict_proba(X_BOW_words_not_equal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2345796, 2)\n"
     ]
    }
   ],
   "source": [
    "submission = pd.concat([test_df.test_id.astype(int), pd.DataFrame(predicted[:,1], \n",
    "                                        columns=['is_duplicate'], index=test_df.index)], axis=1)\n",
    "print submission.shape\n",
    "submission_BOW_words_not_equal = save_submission(submission, 'submission_BOW_words_not_equal', with_dttm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#models_and_test_matricies['BOW_words_not_equal'] = (model_lr_BOW_words_not_equal, X_BOW_words_not_equal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#with open('models_and_test_matricies.pkl', 'wb') as fid:\n",
    "    #cPickle.dump(models_and_test_matricies, fid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Извлечение признаков: TF-IDF </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import paired_cosine_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TFIDF = TfidfVectorizer(preprocessor=nlp_preprocessor, tokenizer=nlp_tokenizer, analyzer='word', max_df=0.999, min_df=20, \n",
    "                        norm='l2', use_idf=True, smooth_idf=True)\n",
    "TFIDF.fit(pd.concat((train_df['question1'],train_df['question2'])).unique())\n",
    "\n",
    "TFIDF_q1 = TFIDF.transform(train_df.question1)\n",
    "TFIDF_q2 = TFIDF.transform(train_df.question2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404288, 9281)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFIDF_q1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404288L, 1L)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = train_df.is_duplicate.values\n",
    "X_TFIDF = paired_cosine_distances(TFIDF_q1,TFIDF_q2).reshape(-1, 1)\n",
    "X_TFIDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_lr_tfidf = LogisticRegression(C=0.1, solver='sag', class_weight={1: 0.46, 0: 1.32}, max_iter=10000).fit(X_TFIDF, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('data/test.csv')\n",
    "test_df.loc[test_df['question1'].isnull(), ['question1','question2']] = ''\n",
    "test_df.loc[test_df['question2'].isnull(), ['question1','question2']] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "TFIDF_q1 = TFIDF.transform(test_df.loc[:,'question1'])\n",
    "gc.collect()\n",
    "TFIDF_q2 = TFIDF.transform(test_df.loc[:,'question2'])\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_TFIDF = paired_cosine_distances(TFIDF_q1,TFIDF_q2).reshape(-1, 1)\n",
    "del TFIDF_q1, TFIDF_q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = model_lr_tfidf.predict_proba(X_TFIDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2345796, 2)\n"
     ]
    }
   ],
   "source": [
    "submission = pd.concat([test_df.test_id.astype(int), pd.DataFrame(predicted[:,1], \n",
    "                                        columns=['is_duplicate'], index=test_df.index)], axis=1)\n",
    "print submission.shape\n",
    "submission_tfidf = save_submission(submission, 'submission_tfidf', with_dttm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#models_and_test_matricies['TFIDF'] = (model_lr_tfidf, X_TFIDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3>Использование нескольких моделей: усреднение</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#subm_1 = pd.read_csv('./answers/1/submission_BOW_chars_2017-05-08_19-53-25.csv')\n",
    "#subm_2 = pd.read_csv('./answers/1/submission_BOW_words_2017-05-09_06-02-19.csv')\n",
    "#subm_mean = pd.DataFrame(subm_1)\n",
    "#subm_mean['is_duplicate'] = (subm_1['is_duplicate'] + subm_2['is_duplicate']) / 2\n",
    "#save_submission(subm_mean, 'submission_BOW_mean', with_dttm=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "submission_2017-05-07_21-33-18.csv 0.36967<br>\n",
    "submission_BOW_words_2017-05-09_06-02-19.csv 0.36584<br>\n",
    "submission_BOW_mean 0.35549"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
